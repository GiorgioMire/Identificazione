\chapter{Algoritmo Metropolis Hasting}
Supponiamo di voler estrarre campioni da una distribuzione p(x) nota, difficile da
campionare direttamente.
Si può  chiedere che la distribuzione obiettivo sia
distribuzione di regime di una catena di Markov.\\ 
Un processo stocastico markoviano o processo di Markov è un processo stocastico $\{X(t_n)\}_n$ nel quale la probabilità di transizione che determina il passaggio a uno stato di sistema dipende unicamente dallo stato di sistema immediatamente precedente e non dal come si è giunti a tale stato. Formalmente
\begin{equation}
P(X(t_{n+1})\leq x_{n+1}|X(t_n)= x_n, X(t_{n-1})= x_{n-1}, \ldots, X(t_0)= x_0) = P(X(t_{n+1})\leq x_{n+1}|X(t_n)=x_n)
\end{equation}
Ogni catena di Markov è caratterizzata da un operatore di transizione che mappa la densità di probabilità sugli stati al tempo attuale in quella al tempo successivo. Per fare una analogia, nelle catene a stato discreto e finito l'operatore era  rappresentato dalla matrice di transizione mentre nelle catene a stato continuo è dato dal il funzionale
\begin{equation}
Tr[\bullet]=\int \bullet(x)s(x'|x)dx
\end{equation}
Dove $s(x'|x)$ è una funzione di due variabili di stato che descrive la probabilità di transitare dal vecchio stato $x$ al nuovo stato $x'$ ed è detto kernel.
 Una catena si dice ergodica se
dopo un certo tempo (transitorio iniziale) , essa converge all'unica distribuzione
di regime indipendentemente dalla distribuzione di partenza.
Le condizioni necessarie per l’ergodicità   della catena sono:
\begin{itemize}
\item \textbf{irriducibilità} : la probabilità   di visitare ciascuno stato a partire da ciascuno
stato è   strettamente positiva
\item \textbf{aperiodicità} : una catena è periodica se può  ritornare in un certo stato solo
a istanti multipli di un qualche intero maggiore di 1. Una catena è   aperiodica
se non è   periodica.
\end{itemize}

In poche parole, fissato un qualsiasi istante abbastanza grande e un qualsiasi stato,
deve essere possibile una storia temporale della catena che la porta a risiedere in
quello stato a quell’istante. La questione diventa quindi come scegliere il kernel
\begin{equation*}
s(x' |x) 
\end{equation*}
(probabilità   di transizione dal vecchio stato m al nuovo stato m' ) della catena,
in modo che la catena sia ergodica e che la distribuzione di regime sia proprio p(m).
Una condizione sufficiente non necessaria è   che la distribuzione obiettivo soddisfi la
condizione di reversibilità (detta anche di bilancio dettagliato).
Questa proprietà, nella sua forma generale dice che la probabilità di risiedere in un sottoinsieme A dello spazio di stato e di transitare in un sottoinsieme B, deve essere la stessa qualora si scambino i ruoli dei sottoinsiemi.\\
Formalmente 
\begin{equation}
\int_{(x,x')\in A\times B}p(x)s(x' |x) dx dx'= \int_{(x,x')\in A\times B}p(x')s(x|x' )dx dx'
\end{equation}
che vale sicuramente se
\begin{equation}
p(x)s(x' |x) = p(x')s(x|x' )
\end{equation}

Una  densità   di probabilità   $\ph$ è   detta stazionaria se è   autofunzione
dell’operatore di transizione della catena, ovvero\\
\begin{equation}
Tr[\ph]=\ph
\end{equation}
e semplice dimostrare che se vale la condizione di reversibilità   allora la distribuzione
è   stazionaria infatti
\begin{equation*}
\begin{split}
Tr[\ph]=\int \ph(x)s(x'|x)dx=\int \ph(x')s(x|x')dx=\\
\ph(x')\int s(x|x')dx=\ph(x')\cdot 1=\ph(x')
\end{split}
\end{equation*}
Si dimostra inoltre che se vale la condizione di reversibilità allora la probabilità della catena di Markov converge alla probabilità stazionaria.\\
Si definisca la distanza della distribuzione attuale da quella stazionaria\\
\begin{equation}
D=\int_x \left\vert (p(x) - \ph(x))\right\vert dx 
\end{equation}
La distanza al passo seguente sarà
\begin{equation}
\begin{split}
D'=\int_{x'} \left\vert (Tr[p(x)] - \ph(x')\cdot 1) \right\vert dx'\\
=\int_{x'} \left\vert (\int_{x}p(x)s(x'|x)dx - \ph(x')\int_{x}s(x|x')dx) \right\vert dx'=\\
=\int_{x'} \left\vert(\int_{x}p(x)s(x'|x)dx  - \int_{x}\ph(x')s(x|x')dx) \right\vert dx'=\\
=\int_{x'} \left\vert(\int_{x}p(x)s(x'|x)dx  - \int_{x}\ph(x)s(x'|x)dx) \right\vert dx'=\\
=\int_{x'} \left\vert (\int_{x}[p(x)-\ph(x)]s(x'|x)dx ) \right\vert dx'=\\
\end{split}
\end{equation}
Applicando la disuguaglianza triangolare  e usando il fatto che la ddp è non negativa
\begin{equation}
\begin{split}
 \left\vert \int_{x}[p(x)-\ph(x)]s(x'|x )dx \right\vert \leq    \int_{x}\left\vert[p(x)-\ph(x')]s(x'|x)\right\vert dx \\
 =\int_{x} \left\vert[p(x)-\ph(x)]\right\vert   s(x'|x)dx \\
\end{split}
\end{equation}

quindi
\begin{equation}
\begin{split}
D'\leq\int_{x}\int_{x'} \left\vert[p(x)-\ph(x)]\right\vert  s(x'|x)dx dx'=\\
 \int_{x}\left\vert[p(x)-\ph(x)]\right\vert   \int_{x}s(x'|x)dx'dx \\
 \int_{x} \left\vert[p(x)-\ph(x)]\right\vert dx =D\\
\end{split}
\end{equation}
La distanza al passo successivo è sempre minore o uguale a quella precedente.\\
In realtà affinchè la distanza si mantenga uguale con la transizione è necessario che $p(x)-\ph(x)$ abbia lo stesso segno per ogni $x'$
cosa che non può accadere perchè le due quantità che si sottraggono sono entrambe normalizzate a 1.\\
L'unico caso in cui la distanza si mantiene è proprio quando è nulla.






Se si sceglie un kernel arbitrario uguale ad una probabilità   di transizione facile
da campionare $s(\direct) = q(\direct) $ solitamente la condizione di reversibilità   non è   
soddisfatta. Solitamente si ha uno sbilanciamento che significa che alcune transizioni
sono più  probabili in un certo verso.
\begin{equation}
\ph(x)s(\direct)>\ph(x')s(\inverse)
\end{equation}

In tal caso, viste le distribuzioni di partenza e la probabilità   di transizione scelta è   
più  probabile osservare la transizione $x\rightarrow x'$ piuttosto che la transizione $x'\rightarrow x$
\\Si cerca quindi di ristabilire l’equilibrio scegliendo come kernel la probabilità   di
transizione moltiplicata per un fattore correttivo 
\begin{equation}
q(\direct) = \gamma(\direct)q(\direct)
\end{equation}
In particolare si può  interpretare $\gamma(\direct)$ come la probabilità   di accettare la mossa $x \rightarrow x'$. Imponendo quindi che valga


\begin{equation}
\ph(x)\gamma(\direct)q(\direct)=\ph(x')\gamma(\inverse)q(\inverse)
\end{equation}
si ricava
\begin{equation}
\frac{\gamma(\direct)}{\gamma(\inverse)}=\frac{\ph(x')q(\inverse)}{\ph(x)q(\direct)}
\end{equation}

Perchè   si abbia coerenza con la eq (3.4) bisogna che il rapporto al membro sinistro sia minore di 1. In particolare si può scegliere

\begin{itemize}
\item $\gamma(\inverse)=1$ che equivale ad accettare tutte le transizioni $m' \rightarrow m$ che sono meno
frequenti
\item $\gamma(\direct)=min\left\lbrace 1,\frac{\ph(x')q(\inverse)}{\ph(x)q(\direct)}\right\rbrace$ fattore di riduzione delle transizioni più  frequenti
\end{itemize}
\newpage
 L'algoritmo MH è    così definito\vspace{1em}\\
\hrule 
\textbf{Algoritmo} Metropolis Hastings
\hrule



\begin{algorithmic}
\State Inizializza  $X_0=x_0$
\For {$t=0,1,2\dots T$}
    \State $i\gets 0$

\State Estraggo la proposta per il nuovo stato $x^t \sim q(x^t |X_t)$
\State Calcolo la probabilità di accettare la mossa $\gamma(\direct)=min\left\lbrace 1,\frac{\ph(x^t)q(X_t | x^t)}{\ph(X_t)q(x^t|X_t  )}\right\rbrace$
\State Estraggo una variabile da una distribuzione uniforme $u\sim U(0,1)$
\If {$u \leq \gamma(x^t | X_t)$}
 \State La catena transita nel nuovo stato proposto $X_{t+1}=x^t$
\Else
\State La catena rimane nel vecchio stato $X_{t+1}=X_t$
\EndIf
\EndFor
\end{algorithmic}

