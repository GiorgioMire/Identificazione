\documentclass[10pt,a4paper,oneside,openany,noindent]{report}
\usepackage[utf8]{inputenc}
\usepackage{amsmath}
\usepackage{amsfonts}
\usepackage{amssymb}
\usepackage{graphicx}
\usepackage{subfigure}
\usepackage[margin=3cm]{geometry}
\usepackage{amssymb}
\usepackage{graphicx}
\setlength\parindent{0pt}
\usepackage[pagestyles]{titlesec}
%\titleformat{\chapter}[display]{\normalfont\bfseries}{}{0pt}{\Huge}
\newpagestyle{mystyle}
{\sethead[\thepage][][\chaptertitle]{}{}{\thepage}}
\pagestyle{mystyle}
\usepackage{algorithm}
\usepackage{algpseudocode}
\input{newcommands}
\usepackage[]{frontespizio}
\begin{frontespizio}
\Universita{Università di Pisa}
\Universita {Università di Pisa}
\Logo [1.5cm]{4362142973_41e74dbc81_b.jpg}
\Facolta {DIPARTIMENTO DI INGEGNERIA DELL’INFORMAZIONE}
\Corso [Laurea]{Ingegneria robotica e dell’automazione}
\Annoaccademico{2015-2016}
\Titoletto {Progetto per il corso di identificazione dei sistemi incerti}
\Titolo {Identificazione di sistemi mediante modello NARMAX e
approccio bayesiano}
\Candidato [453645]{Giorgio Mirenda}
\Relatore {prof. Andrea Caiti}
\end{frontespizio}
\begin{document}
\hspace{1em}
\newpage

\chapter{Introduzione}
\section*{Premessa}

Questo relazione rappresenta il progetto per l'esame \emph{Identificazione dei Sistemi Incerti} del corso di studi di Ingegneria Robotica e dell'Automazione di Pisa uno studio critico dell'articolo di ricerca \textit{Computational system identification for Bayesian
NARMAX modelling} di Tara Baldacchino, Sean R. Anderson  e Visakan Kadirkamanathan.
\section*{Motivazioni}
Quando si vuole identificare un sistema dinamico bisogna
\begin{itemize}
\item stabilire la struttura del legge dinamica
\item stabilire il valore numerico delle costanti del modello
\end{itemize}
La prima richiesta consiste nel decidere il tipo e il numero di operazioni sui segnali di ingresso e di stato che sono in grado di riprodurre accettabilmente ( e possibilmente con una legge compatta) la dinamica del sistema.
La seconda richiesta consiste invece nel determinare il valore numerico dei parametri che intervengono.\\


I casi in cui è sufficiente una identificazione parametrica sono i casi in cui si ha già la struttura della legge. Per ottenere la legge (a meno del valore delle costanti) è necessario uno studio del sistema a partire dai principi primi che regolano tutti i fenomeni che sono coinvolti. In definitiva l'identificazione parametrica è sufficiente solo se sono verificate le seguenti condizioni
\begin{itemize}
\item è \textbf{possibile} ottenere una descrizione del sistema applicando i principi primi delle scienze
\item è \textbf{vantaggioso} ottenere una descrizione del sistema applicando i principi primi delle scienze (tempo speso, rischio di errori etc)
\item ci si accontenta della descrizione ottenuta applicando i principi primi delle scienze (rischio di tralasciare fenomeni importanti)
\item la complessità delle leggi che si ottengono applicando i principi primi delle scienze non è tale da renderle inutilizzabili
\end{itemize}

Quando una di queste condizioni non è soddisfatta è possibile inserire nel processo di identificazione anche la ricerca della struttura del modello.
A tale scopo si ipotizza una classe (abbastanza vasta) di strutture di modello
e si lascia al processo di identificazione l’onere di scegliere quella che maggiormente si adatta
alle misure e alle preferenze di modellazione. I metodi Bayesiani in particolare sono appropriati per la selezione dei
modelli perchè forniscono naturalmente (senza analisi aggiuntve) un contesto in cui
si quantifica l’incertezza associata all’identificazione. L’approccio bayesiano infatti, non fornisce una singola descrizione del sistema ma fornisce una distribuzione di
probabilità associata al set di modelli possibili. Dunque risolvere il problema di
inferenza bayesiana conduce a scelte più  ponderate rispetto alla semplice estrazione
del modello che si adatta meglio ai dati reali. Analizzando la distribuzione prodotta
si può per esempio individuare un modello poco meno accurato del migliore ma
preferirlo perchè meno complesso .\\
Nella seguente trattazione la classe di modelli scelta è quella dei nonlineari, auto-regressivi, a media mobile
con ingressi esogeni (NARMAX); essa è una popolare classe modelli ingresso-uscita
spesso usata nell’identificazione di sistemi non lineari in vari ambiti dell’ingegneria
(e non) poichè ha il pregio di produrre leggi compatte ma accurate.
Come si vedrà nei successivi capitoli, ciascun modello NARMAX può essere visto
come lo sviluppo su una opportuna base polinomiale della legge che
regola il sistema. Ciò che distingue un modello da un altro è il numero e l’insieme
dei termini presenti nello sviluppo.

La ricerca esaustiva tra tutte le possibili combinazioni di termini NARMAX è tuttavia quasi sempre computazionalmente improponibile , così si è puntato negli ultimi
anni a sviluppare metodi di campionamento efficaci che, avvalendosi di una catena
di Markov opportunamente costruita, esplorano in maniera non esaustiva l’insieme
dei modelli ottenendo comunque statistiche significative.
\chapter{Identificazione bayesiana e metodi
di campionamento Monte Carlo}
\section{Approccio Bayesiano per l’identificazione}
L’inferenza bayesiana è un approccio all’inferenza statistica in cui le probabilità
non sono interpretate come frequenze ma piuttosto come livelli di fiducia nel verificarsi di un dato evento. Il nome deriva dal teorema di Bayes, che costituisce il
fondamento di questo approccio. Gli statistici bayesiani sostengono che i metodi
dell’inferenza bayesiana rappresentano una formalizzazione del metodo scientifico,
che normalmente implica la raccolta di dati che avvalorano o confutano una data
ipotesi.
Queste caratteristiche rendono l’approccio bayesiano un utile ausilio per discriminare tra alternative in conflitto e dunque un ottimo strumento per l’identificazione
dei sistemi.
Il metodo usa una stima del grado di fiducia in una data ipotesi prima dell’osservazione
dei dati al fine di associare un valore numerico al grado di fiducia in quella stessa
ipotesi successivamente all’osservazione dei dati. Si supponga di voler identificare
un sistema scegliendo il più adatto in un insieme M di modelli.
Sia M una variabile aleatoria che rappresenta la legge che regola il vero sistema.
L’obiettivo dell’identificazione bayesiana è quello di calcolare per ogni $m\in M$ la
probabilità a posteriori
\begin{equation} P (M = m|Y )
\end{equation}
dunque complessivamente determinare la distribuzione della probabilità sull’insieme
dei modelli condizionatamente alle misure.\\
Una volta stimata la probabilità a posteriori, è possibile utilizzare il criterio MAP
\begin{equation}
m=arg \min_m P(M = m|Y )
\end{equation} oppure vari altri criteri per estrarre il modello da utilizzare.\\
La probabilità condizionata è stata definita in termini della probabilità congiunta e
marginale dei due eventi
\begin{equation}
P (M = m|Y ) =\frac{
P (M = m, Y )}{
P (Y )}
\end{equation}

la definizione corrisponde all’idea ragionevole che se fisso il valore di $Y$ allora
\begin{equation}
P (M = m|Y ) \propto P (M = m, Y )
\end{equation}

Avendo però ristretto l’insieme di supporto su cui è definita la metrica di probabilità (rispetto a quello della congiunta),
è necessario imporre che valgano ancora gli assiomi della probabilità, in particolare
chiamando k la costante di proporzionalità e integrando su tutti i casi possibili si ha
\begin{equation}\int P (M = m|Y )dm =
k \cdot \int P (M = m, Y )dm = k \cdot P (Y ) := 1\end{equation}
da cui si ricava il valore di k
\begin{equation}
k =\frac{1}{P(Y)}
\end{equation}
ottenendo la definizione di probabilità condizionata.
Scambiando i ruoli delle variabili aleatorie si ha anche che
\begin{equation}
P (Y |M = m) =\frac{
P (M = m, Y )}{
P (M = m)}
\end{equation}


dunque mettendo insieme le equazioni (2.3) e (2.7) si ottiene la formula di Bayes
\begin{equation}
P (M = m|Y ) =\frac{
P (Y |M = m)P (M = m)}{
P (Y )}
\end{equation}

usando il teorema della probabilità totale si può inoltre esprimere la costante al
denominatore in funzione delle quantità al numeratore ottenendo
\begin{equation}
P (M = m|Y ) =\frac{
P (Y |M = m)P (M = m)}{\int
P (Y |M = m)P (M = m)dm}
\end{equation}
Nei problemi di identificazione l’espressione della probabilità a posteriori è quasi
sempre impossibile da valutare analiticamente sopratutto per colpa dell’integrale al
denominatore che deve essere calcolato su tutti i possibili modelli; si ricorre quindi a
metodi numerici di tipo Monte Carlo basati sul campionamento della distribuzione.
Spesso risulta impossibile anche campionare direttamente la distribuzione e se ne
deve ottenere una stima accettando o scartando opportunamente i campioni estratti
da una distribuzione più semplice.
\section{Idea dei metodi Monte Carlo}
I metodi Monte Carlo sfruttano il seguente ragionamento: se si vuole  campionare una distribuzione con densità $p(x)$ (nel nostro caso la posterior sui modelli) si ha
\begin{equation}
p(x)=p(x)\otimes \delta(x)=\int_\xi p(\xi)\delta(x-\xi)d\xi
\end{equation}
se poi $p(x)$ è fattorizzabile come \begin{equation}
p(x)=q(x)g(x)
\end{equation}
tale che $q(x)$ sia una densità di probabilità ovvero
\begin{itemize}
\item $q(x)>0$ per ogni $m$
\item $\int_m q(x)=1$
\end{itemize} allora
\begin{equation}
p(x)=\int_\xi q(\xi)g(\xi)\delta(x-\xi)= E[g(Q)\delta(x-Q)]
\end{equation}
con $Q$ variabile aleatoria avente come densità $q(\cdot)$.
Usando uno stimatore si può approssimare il valore atteso come
\begin{equation}
E[g(Q)\delta(x-Q)]\simeq \frac{1}{N}\sum_{k=1}^N g(q_k)\delta(x-q_k)
\end{equation}
con $q_k\sim q(\cdot)$ campione estratto dalla distribuzione di densità di proposal $q(\cdot)$
In pratica si estraggono numerosi modelli da una distribuzione di proposal $q(\cdot)$,
e si costruisce un istogramma pesato con i pesi 
\begin{equation}
g(q_k)=\frac{p(q_k)}{q(q_k)}
\end{equation}
Si noti che nella formula dei pesi la desnsità  $p(\cdot)$ è solamente una funzione da valutare in uno specifico modello, cosa che quasi sempre è fattibile  perchè richiede una informazione che è locale nello spazio dei modelli, al contrario del problema di campionare direttamente la densità che richiederebbe una conoscenza della funzione su tutto lo spazio.\\
\section{Importance sampling: scelta della proposal}
In teoria le precedenti considerazioni sono già sufficienti per campionare la distribuzione, in pratica la scelta di una proposal opportuna è critica per l'accuratezza dell'algoritmo. Avendo a disposizione un tempo limitato, e quindi un numero limitato di campioni si otterrà solo una approssimazione della distribuzione cercata.\\
La proposal è determinante nell'imporre alcuni criteri di approssimazione\\
Partendo dal presupposto ovvio che non è possibile esplorare esaustivamente lo spazio dei modelli, bisogna fare delle assuzioni su quali regioni dello spazio dei modelli esplorare maggiormente (e quindi descrivere) e quali invece trascurare.\\
E' sensato disinteressarci delle regioni in cui i modelli hanno bassa probabilità.
Ai fini dell'identificazione, non ci interesserà mai confrontare due modelli con probabilità bassa. Si può benissimo sbagliare o ignorare il rapporto reciproco tra le loro probabilità per concentrarsi sulla descrizione delle regioni dove i modelli hanno probabilità più alta.
Questo induce a scegliere la proposal quanto più simile alla posterior, in modo da estrarre campioni prevalentemente dove la posterior è alta.
Tale criterio è detto di \emph{importance sampling}.\\ \\
Al limite se riuscissi ad essere sicuro che sto campionando da $q(\cdot)=p(\cdot)$ 
avrei che i pesi si ridurrebbero a
\begin{equation}
g(q_k)=\frac{p(q_k)}{q(q_k)}=\frac{p(q_k)}{p(q_k)}=1
\end{equation}
e dunque
\begin{equation}
p(x)\simeq \frac{1}{N}\sum_{k=1}^N \delta(x-q_k)
\end{equation}
Ovvero potrei avere una approssimazione di $p(\cdot)$ semplicemente valutando la frequenza relativa con cui è stato estratto $q_k=x$.
Attenzione, l'ipotesi di sapere che $q(\cdot)=p(\cdot)$ non vuol dire che conosco la forma della funzione su tutto lo spazio, ma solo che
\begin{itemize}
\item so valutare la funzione in un particolare modello
\item ho un metodo (anche indiretto) per campionare la funzione
\end{itemize}

Gli algoritmi Monte Carlo Markov Chain, infatti, ottengono i modelli $q_k$ 
come stati di una catena di Markov costruita sullo spazio dei modelli.\\ A  tale catena si chiede di avere come unica probabilità di regime proprio $p(\cdot)$.\vspace{2em}\\
Dopo un transitorio iniziale la catena finirà per campionare gli stati dalla distribuzione di regime $p(\cdot)$.
\input{1MetropolisHastings}
\input{RJMCMC}
\input{Modello}
\input{Algoritmo}
\input{besag}
\input{tuning}
\include{correzionesegno}
\section*{Test dell'algoritmo}
In questa sezione vengono mostrati i risultati ottenuti dalla mia implementazione dell'algoritmo nel caso proposto come esempio dall'articolo.\\ \vspace{2em}
L'equazione alle differenze da identificare è
\begin{align*}
y(t)=&0.6y(t-2)-0.5u(t-1)y(t-1)-0.7u(t-2)^2\\
&+0.7u(t-2)^2y(t-2)+0.2e(t-1)^1-0.3u(t-1)e(t-2)+e(t)
\end{align*}
\vspace{2em} \\
I risultati sono riassunti nella seguente tabella, di seguito si entrerà nel dettaglio della spiegazione e dell'analisi dell'esecuzione dell'algoritmo. \vspace{2em} \\
\begin{tabular}{|p{8em}|p{4em}|p{8em}|p{8em}|p{4em}|p{4em}|}
\hline
Termine & Presente  nel target? & Coefficiente Target & Coefficiente identificato & Confidenza & Bin Size\\
\hline
$y(t-2)$ & SI & 0.6 & 0.60404 &  0.7011 & 0.0161 \\ 
\hline
$u(t-1)y(t-1)$ & SI &  -0.5 &  -0.4992  &  0.7925 &   0.0147\\
\hline
$u(t-2)^2$ & SI &  -0.7 &  -0.6939  &  0.2068 &   0.0093\\ 
\hline
$u(t-2)^2y(t-2)$ & SI &   0.7 &   0.7002  &  0.4239  &  0.0113\\ 
\hline
$e(t-1)^1$  & SI &  0.2  &  0.2146  &  0.1403 &   0.0131\\
\hline 
 $u(t-1)^1e(t-2)^1$  & SI & -0.3 &  -0.3383  &  0.0558  &  0.0104\\
\hline 
\end{tabular}
\vspace{2em} \\


Per l'esecuzione sono stati simulati i dati di ingresso e di uscita.\\
Nella costruzione, l'uscita simulata è stata volutamente sporcata dldisturbo bianco.\\
\[u(t)\sim \mathcal{U}(-1,1)\]
\[e(t)\in \normal{0}{\sigma^2_e} \hspace{3em} \sigma_e=0.1\]
Nonostante i segnali siano stati generati con i generatori pseudocasuali di Matlab, è stato verificato 
graficando la funzione di autocorrelazione che essi siano veramente bianchi \\
L'uscita $y(t)$ è stata calcolata applicando ricorsivamente l'equazione alle differenze da identificare.\\
Con tali scelte sono stati ottenuti i seguenti rapporti segnale-rumore
\begin{equation}
SNRu =15.2 dB
\end{equation}
\begin{equation}
SNRy=23.6 dB
\end{equation}
Il setting dei parametri statici e le condizioni iniziali dei parametri dinamici sono i seguenti

\begin{tabular}[t] {|p{10em}|p{0.5\linewidth}|}
\hline
\[lambdaA=2\]
\[lambdaB=2\]
& Valore  atteso iniziale del numero di parametri  \\ \hline

\[sigmaA=5\]
\[sigmaB=5\] &
 Inizializzazione delle varianze delle proposal dei coefficienti\\ \hline
\[c=0.3\] & Rapporto di frequenza tra le mosse dinamiche (morte e nascita) e quella
 di aggiornamento\\ \hline
 \[dynamicOrderP=2 \hspace{1em}\]
\[dynamicOrderN=2 \hspace{1em}\] & Massimo ritardo che compare nei termini disponibili rispettivamente di processo e di rumore.  \\ \hline
\[polinomialOrderP=3\]
\[polinomialOrderN=3\] & Massimo grado polinomiale possibile \\ \hline


\[alphaLA=0.5;\]\[alphaLB=0.5;\]  & Iperparametro di forma \\ \hline


\[betaLA=1.1;\]\[betaLB=1.1;\]  &Iperparametro di scala \\ \hline

\hline
\end{tabular}
\vspace{2em}
\\
Sono state eseguite 30000 iterazioni per studiare l'andamento temporale dell'algoritmo.\\
Tuttavia la convergenza (almeno in termini di struttura del modello) richiede meno iterazioni come si evince dai grafici seguenti 
\begin{figure}[ht]
\quad
\centering
\begin{minipage}[t]{0.45\linewidth}

\includegraphics[width=0.7\textwidth]{modesk.eps} 
\caption{Miglior numero di termini di processo in funzione del numero di iterazioni.   }
\label{fig:minipage1}
\end{minipage}
\quad
\begin{minipage}[t]{0.45\linewidth}
\centering
\includegraphics[width=0.7\textwidth]{BestModelPTransitorio.eps}
\caption{Identificativo del miglior  modello di processo in funzione del numero di iterazioni (Dettaglio del transitorio)}
\label{fig:minipage2}
\end{minipage}
\end{figure}

\begin{figure}[ht]
\quad
\centering
\begin{minipage}[t]{0.45\linewidth}

\includegraphics[width=0.7\textwidth]{modesq.eps} 
\caption{Miglior numero di termini di rumore in funzione del numero di iterazioni.   }
\label{fig:minipage1}
\end{minipage}
\quad
\begin{minipage}[t]{0.45\linewidth}
\centering
\includegraphics[width=0.7\textwidth]{BestModelNTransitorio.eps}
\caption{Identificativo del miglior  modello di rumore in funzione del numero di iterazioni (Dettaglio del transitorio)}
\label{fig:minipage2}
\end{minipage}
\end{figure}
In particolare si ha che l'algoritmo 

\begin{itemize}
\item identifica correttamene il numero di termini di processo $k=4$  in 454 iterazioni
\item identifica correttamene il numero di termini di rumore $q=2$  in 2598 iterazioni
\item identifica correttamene la struttura del modello di processo  in 414 iterazioni
\item identifica correttamene la struttura del modello di rumore  in 93 iterazioni
\end{itemize}
La convergenza dell'algoritmo per quanto riguarda i coefficienti è più difficile da provare in quanto si hanno a disposizione meno iterazioni (quelle in cui la catena è andata a risiedere in un modello con la struttura corretta).\\
Si prenda ad esempio l'andamento del miglior coefficiente $a_2$ nel senso di
\[\arg \max p(a_2|y,P_k,k)\] graficato qui sotto
\begin{center}
\includegraphics[width=0.4\linewidth]{bestcoeffak2eps.eps} 
\end{center}
Si può notare che  dopo 20000 iterazioni si ha ancora una fluttuazione del miglior coefficiente, cosa che potrebbe far dubitare della convergenza. La fluttuazione è però di 0.003 mentre l'ultima dimensione del bin per l'istogramma è 0.017. In realtà tutte le fluttuazioni (da quando la catena risiede per la prima volta nella struttura corretta del modello) sono di entità paragonabile.\\
Si può ritenere dunque che l'algoritmo abbia portato in convergenza il coefficiente al valore\\ $-0.5\pm 0.003$ almeno a partire dall'iterazione 9000 (risultato che conferma la scelta degli autori dell'articolo di fermarsi a 9500 iterazioni)










\begin{figure}[ht]
\quad
\centering
\begin{minipage}[b]{0.45\linewidth}
\centering
\includegraphics[width=0.7\textwidth]{histk.eps} 
\caption{Probabilità a posteriori del numero di termini }
\label{fig:minipage1}
\end{minipage}
\quad
\begin{minipage}[b]{0.45\linewidth}
\centering
\includegraphics[width=0.7\textwidth]{histq.eps}
\caption{Densità di probabilità di $a_2$ a posteriori}
\label{fig:minipage2}
\end{minipage}
\end{figure}


\begin{figure}[ht]
\quad
\centering
\begin{minipage}[b]{0.45\linewidth}
\centering
\includegraphics[width=0.7\textwidth]{ak_1.eps} 
\caption{Densità di probabilità di $a_1$ a posteriori}
\label{fig:minipage1}
\end{minipage}
\quad
\begin{minipage}[b]{0.45\linewidth}
\centering
\includegraphics[width=0.7\textwidth]{ak_2.eps}
\caption{Densità di probabilità di $a_2$ a posteriori}
\label{fig:minipage2}
\end{minipage}
\end{figure}

\begin{figure}[ht]
\centering
\begin{minipage}[b]{0.45\linewidth}
\centering
\includegraphics[width=0.7\textwidth]{ak_3.eps}
\caption{Densità di probabilità di $a_3$ a posteriori}
\label{fig:minipage1}
\end{minipage}
\quad
\begin{minipage}[b]{0.45\linewidth}
\centering
\includegraphics[width=0.7\textwidth]{ak_4.eps}
\caption{Densità di probabilità di $a_4$ a posteriori}
\label{fig:minipage2}
\end{minipage}
\end{figure}


\begin{figure}[ht]
\begin{minipage}[b]{0.45\linewidth}
\centering
\includegraphics[width=0.7\textwidth]{bq_1.eps}
\caption{Densità di probabilità di $b_1$ a posteriori}
\label{fig:minipage1}
\end{minipage}
\quad
\begin{minipage}[b]{0.45\linewidth}
\centering
\includegraphics[width=0.7\textwidth]{bq_2.eps}
\caption{Densità di probabilità di $b_2$ a posteriori}
\label{fig:minipage2}
\end{minipage}\\
\end{figure}


\end{document}
