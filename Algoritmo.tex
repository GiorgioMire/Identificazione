\chapter{Algoritmo RJMCMC per
l’identificazione di modelli
NARMAX}

 L'algoritmo MH è così definito\vspace{1em}\\
\hrule 
\textbf{Algorithm} RJMCMC for NARMAX identification
\hrule



\begin{algorithmic}
\State fissa i parametri di tuning $c$ e $\ve$
\State inizializza$\left(k^{(0)},q^{(0)},\pk^{(0)},\eq^{(0)},\ak^{(0)},\bq^{(0)},\la^{(0)},\lb^{(0)},\sigma_a^{(0)},\sigma_b^{(0)}\right)$
\vspace{2em}
\For {$i=1:N_{\text{iter}}$}
    \State Estrai $z_k\sim \unif$
    \If {$z_k\leq B_k^{(i)}$}
    \State Effettua la mossa di nascita (Algoritmo 1)
    \ElsIf{$z_k\leq B_k^{(i)}+D_k{(i)}$}
\State Effettua mossa di morte (Algoritmo 2)
\Else
\State Aggiorna i parametri (Algoritmo 3)
\State Aggiorna la varianza dei  parametri
\EndIf
\State Estrai $\lb^{(i)}\sim p(\lb|q^{(i)})$
\vspace{2em}
\If {$i>$}
    \State Estrai $z_q\sim \unif$
    \If {$z_q\leq B_q^{(i)}$}
    \State Effettua la mossa di nascita (Algoritmo 1)
    \ElsIf{$z_k\leq B_q^{(i)}+D_q{(i)}$}
\State Effettua mossa di morte (Algoritmo 2)
\Else
\State Aggiorna i parametri (Algoritmo 3)
\State Aggiorna la varianza dei  parametri
\EndIf
\EndIf
\vspace{2em}
\State Calcola l'errore residuo $\epsilon^{(i)}=\y-\pk^{(i)}\ak^{(i)}-\eq^{(i)}\bq^{(i)}$:assumilo come stima del segnale di  rumore
\State Aggiornamento di $\eq^{(i)}$ in base alla nuova stima
\EndFor
\end{algorithmic}

L’algoritmo parte con l’inizializzazione di parametri e iperparametri: solitamente si
inizia con un modello vuoto ovvero con nessun termine (di rumore e di processo),
le matrici di regressione sono in tal caso (per convenzione) una singola colonna
di elementi nulli e il vettore dei parametri è lo scalare nullo. Gli iperparametri
delle poisson troncate vengono inizializzati a quello che ci si aspetta essere il numero medio di termini nello sviluppo, mentre le varianze dei coefficienti vengono
inizializzate ad un valore non piccolo in modo da avere inizialmente dei prior molto
dispersi e quindi poco informativi. L’inizializzazione di questi parametri non è critica perchè essi verranno aggiornati con l’evoluzione della catena e si adatteranno al
valore più appropriato. La varianza $\ve$ del rumore bianco invece viene inizializzata
e non viene più aggiornata, tale parametro rappresenta infatti un parametro di tuning dell’algoritmo essendo in qualche modo una metrica di affidabilità delle misure,
è sensato dunque che esso influisca direttamente sulla probabilità di accettazione
delle mosse: abbassare tale parametro equivale a ritenere l’incertezza bassa quindi
il rapporto di accettazione sarà più selettivo e le mosse proposte verranno scartate
più frequentemente.
L’algoritmo prevede un numero fissato a priori di iterazioni. In corrispondenza di
ciascuna iterazione la catena di Markov andrà a risiedere in uno stato che rappresenta un modello del sistema. L’assunzione di \textbf{ergodicità} permette di ricostruire la probabilità che la catena risieda in un particolare stato a partire dal
numero di iterazioni medio in cui la catena risiede in quello stato. E’ necessario però
adottare due accorgimenti:
\begin{itemize}
\item il numero di iterazioni deve essere abbastanza elevato da fare in modo che valga
con buona approssimazione l’ipotesi di ergodicità. Se le statistiche si raccolgono su poche iterazioni le probabilità che si ottengono sono molto influenzate
dalla particolare realizzazione della catena.
\item il numero medio di iterazioni in corrispondenza del quale la catena risiede in
un particolare stato deve essere calcolato escludendo le prime iterazioni della
catena (il cosiddetto periodo di burnin), questo perchè
le prime iterazioni sono fortemente influenzate dalla particolare inizializzazione
dei parametri e dello stato.
\end{itemize}
Nel contesto della singola iterazione eseguono due algoritmi analoghi: l’evoluzione
del modello di processo e l’evoluzione del modello di rumore.
Entrambi prevedono una fase in cui si seleziona la tipologia di mossa, una fase in cui
si effettua la mossa scelta e infine una fase in cui si estrae un nuovo iperparametro
per il numero medio di termini.
Dopo che hanno eseguito questi algritmi si calcola il nuovo errore di regressione come
differenza tra le uscite misurate del sistema e le uscite predette dal modello.
Assumendo poi che il modello attuale sia capace di descrivere esattamente l’uscita
misurata, si considera l’errore di regressione come se fosse la realizzazione del rumore gaussiano bianco e si aggiorna la matrice di regressione del rumore.
Per ottenere l’output dell’identificazione basta tenere in memoria (a partire da
quando si ritiene esaurito il transitorio iniziale) i modelli visitati dalla catena e
costruire progressivamente gli istogrammi sul numero di termini, sull’identificativo
dei termini e sul coefficiente associato a ciascun identificativo dei termini. Di seguito
si illustrano le tipologie di mossa previste, il meccanismo di scelta della tipologia di
mossa e nelle sezioni seguenti si entra nel dettaglio di come vengono effettuate le
mosse.
\subsection{Tipologia di mosse}
Le mosse che modificano lo stato della catena, nell’algoritmo dell’articolo sono:
\begin{itemize}
\item Nascita:\\
Viene selezionato un nuovo termine tra quelli rimasti e viene inserito nello
sviluppo polinomiale, togliendolo dall’insieme dei termini disponibili per una
futura mossa di nascita. Il numero di termini del modello passa da $k$ a $k' =
k + 1$.\\
I coefficienti dello sviluppo vengono estratti nuovamente
\item Morte:\\
Viene selezionato un nuovo termine tra quelli presenti nello sviluppo polino-
miale e viene eliminato reinserendolo nell’insieme dei termini disponibili per
una successiva mossa di nascita. Il numero di termini del modello passa da $k$
a $k' = k-1$\\
I coefficienti dello sviluppo vengono estratti nuovamente
\item Aggiornamento:\\
Non si ha cambio di dimensionalità $k'=k$
Vengono solamente cambiati i coefficienti dello sviluppo e la varianza della
distribuzione da cui sono estratti.
\end{itemize}
Mosse analoghe sono previste per i termini di rumore.
Ad ogni iterazione della catena,viene estratta una delle tre mosse.\\
La mossa di nascita viene estratta con probabilità $B_k$ dove
\begin{equation}
B_k=\begin{cases}
1 & k=0\\
0 & k=M_p\\
c\cdot\min\left\lbrace 1,\frac{p(k+1|\la}{p(k|\la)}\right\rbrace & \text{altrimenti}
\end{cases}
\end{equation}
La mossa di morte viene estratta con probabilità
\begin{equation}
D_k=\begin{cases}
0 & k=0\\
c\cdot\min\left\lbrace 1,\frac{p(k-1|\la}{p(k|\la)}\right\rbrace & \text{altrimenti}
\end{cases}
\end{equation}
La mossa di aggiornamento viene estratta con probabilità
\begin{equation}
U_k=1-B_k-D_k
\end{equation}
La costante c serve per regolare la frequenza relativa tra mosse che cambiano la
dimensionalità (morte e nascita) e la mossa di aggiornamento.\\
La scelta delle probabilità di nascita e di morte garantisce che
\begin{equation}
B_k p(k|\lambda)=D_{k+1}  p(k+1|\lambda) \label{equilibr_dimensi}
\end{equation}

La (\ref{equilibr_dimensi}) è una equazione di equilibrio bilanciato per il solo numero di termini.
Questo vuol dire che se si avesse solo l’informazione del numero di termini (nessuna
informazione sui coefficienti o sul tipo di termini,quindi nessuna idea sull’errore di
regressione) la probabilità del numero di termini convergerebbe alla distribuzione a
priori. In realtà nelle prossime sezioni si aggiungerà un meccanismo di accettazione
o rifiuto delle mosse che va di fatto ad alterare la probabilità di regime del numero
di termini in modo da tenere conto anche dell’errore di regressione (informazione
delle misure) piuttosto che delle sole informazioni a priori.
\subsection{Estrazione di una tipologia di mossa}
L’estrazione della tipologia di mosse deve avvenire con le probabilità $B_k$ , $U_k$ , $D_k$
calcolate come descritto nella sezione precedente. Un modo semplice per imporre
tale probabilità è la seguente:\\

\begin{algorithmic}
\State Estrai $z_k\in\unif$
\If {$z_k\leq B_k$}
\State Effettuare la mossa di nascita
\ElsIf {$B_k<z_k\leq B_k+D_k$}
\State Effettuare la mossa di morte
\Else
\State Effettuare la mossa di aggiornamento
\EndIf
\end{algorithmic}
per mostrare che si ottengono effettivamente le probabilità cercate basta integrare
tra gli estremi opportuni la ddp della variabile uniforme che è un l’impulso
rettangolare
\begin{equation}
P\left(0<z_k\leq B_k^{(i)}\right)=\int_0^{B_k^{(i)}}rect(z-0.5)dz=\int_0^{B_k^{(i)}}dz={B_k^{(i)}}
\end{equation}
\begin{equation}
P\left(B_k^{(i)}<z_k\leq B_k^{(i)}+D_k^{(i)}\right)=\int_{B_k^{(i)}}^{B_k^{(i)}+D_k^{(i)}}rect(z-0.5)dz=\int_0^{D_k^{(i)}}dz={D_k^{(i)}}
\end{equation}

\begin{equation}
P\left(B_k^{(i)}+D_k^{(i)}<z_k\leq 1 \right)=\int_{B_k^{(i)}+D_k^{(i)}}^{1}rect(z-0.5)dz=\int_{B_k^{(i)}+D_k^{(i)}}^{1}dz=1-{B_k^{(i)}}-{D_k^{(i)}}=U_k^{(i)}
\end{equation}
con
\begin{equation}
rect(z)=\begin{cases}
0 & abs(z)\leq 0.5\\
1 & abs(z)>0.5 
\end{cases}
\end{equation}

\section{Mossa di nascita}
\hrule 
\textbf{Algorithm 3} Mossa di nacita
\hrule

\begin{algorithmic}
\State All'iterazione $i$ estrai casualmente un termine di processo $p^{(i)}$ quelli non ancora selezionati
\State Calcola la quantità $r_a$
\State Calcola il rapporto di accettazione della mossa di nascita $\gamma_{\textit{birth}}^{(k)}$
\State Estrai $z_b\in\unif$
\If{$z_b\geq\gamma_{\textit{birth}}^{(k)}$}
\State k:=k+1
\State $ \mathcal{P}_k^{(i)}= \mathcal{P}_k^{(i-1)}\cup \{p^{(i)}\} $
\State aggiornare i parametri con il valor medio della proposal $\ak:=\mu_{a,k'}$
\Else
\State Aggiorna i parametri usando (l'algoritmo 3)
\State Aggiorna la varianza $\va$
\EndIf
\end{algorithmic}
\hrule
\vspace{2em}


Il termine da aggiungere nello sviluppo viene scelto casualmente (con probabilità
uniforme) tra i termini disponibili ovvero non già presenti nell’attuale modello.
Una volta scelto il termine candidato è necessario decidere se accettare o meno la
mossa di nascita alla maniera di RJMCMC, in modo da far convergere la catena
all’equilibrio rappresentato dalla posterior dei modelli.\\
\vspace{2em}
In particolare si accetta la mossa di nascita con probabilità
\begin{equation}
\gamma_{\textit{birth}}^{(k)}=min\{1,r_a\}
\end{equation}
a tal fine viene estratto un numero da una distribuzione $z_b\in\unif$,si accetta la
mossa se $z_b\geq \gamma_{\textit{birth}}^{(k)}$ birth e si rifiuta se $z_b> \gamma_{\textit{birth}}^{(k)}$ .
Il rapporto di accettazione $r_a$ viene calcolato come
\begin{equation}
r_a=\frac{\ph(x')g'(u')}{\ph(x)g(u)}\left\vert\frac{\partial(\theta_{k'},u')}{\partial(\theta_{k},u)}\right\vert
\end{equation}
si ha che $\ph$(x ) è la distribuzione target della catena (la posterior) calcolata nel
nuovo stato . Visto che il modello di rumore e gli iperparametri si tengono fissi
durante la transizione si ha che
\begin{equation}
\ph(x')=p(k',\pknew,\aknew|\y,\la,\va)
\end{equation}

si noti che le variabili $k,\pk$, identificano complessivamente una particolare struttura
del modello che è fissata dalla tipologia di mossa, non si ha quindi da effettuare particolari richieste per essi mentre bisogna imporre la condizione di \textit{ dimension matching}
sui vettori dei parametri e delle variabili ausiliarie chiedendo che la trasformazione\\
\begin{equation}
(\ak,u)\rightarrow(\aknew,u')
\end{equation}
sia un diffeomorfismo, si scelgono quindi le variabili ausiliarie in modo che valga.
\begin{equation}
dim(\ak)+dim(u)=dim(\aknew)+dim(u')
\end{equation}
Una possibile scelta è $u = \ak$ e $u' =\aknew$. Il jacobiano del cambio di variabili è
\begin{equation}
\left\vert\frac{\partial(\ak,\aknew)}{\partial(\aknew,\ak)}\right\vert=
\left\vert\frac{\partial\begin{bmatrix}
0 & I_k \\ 
I_{k'} & 0
\end{bmatrix}
 \begin{bmatrix}
\aknew \\ 
\ak
\end{bmatrix} }{\partial(\aknew,\ak)}\right\vert
=\begin{vmatrix}
0 & I_k \\ 
I_{k'} & 0
\end{vmatrix}=|-1|=1
\end{equation}
dunque
\begin{equation}
r_a=\frac{p(k',\pknew,\aknew |\y,\la,\va)p(\ak|\y,k',\pknew,\va)}{p(k,\pk,\ak |\y,\la,\va)p(\aknew|\y,k',\pknew,\va)}
\end{equation}
Per semplificare $r_a$ e evitare di estrarre un vettore $\ak$ dalla distribuzione si può far
uso dell’equazione del candidato di Besag (Si veda in seguito).\\
Con l’equazione di Besag ed alcuni passaggi algebrici, l’espressione di $r_a$ si semplifica
\begin{equation}
r_a=\frac{p(k',\pknew|\y,\la,\va)}{p(k,\pk|\y,\la,\va)}=\frac{\sigma_a^{-k'}\sqrt{det(\canew)}
exp(\mez\muanew^T\invcanew\muanew)p(k'|\la)}{\sigma_a^{-k}\sqrt{det(\canew)}
exp(\mez\mua^T\invca\mua)p(k|\la)} \label{ra}
\end{equation}
dove

\begin{equation}
\ca=\sigma_e^{-2}\pk^T\pk+\sigma_a^{-2}I_k
\end{equation}
\begin{equation}
\mu_{a,k}=\sigma_e^{-2}\ca(\pk^T(\y-\eq\bq) \label{mu}
\end{equation}
Dunque se la mossa di nascita viene accettata, il termine proposto viene aggiunto
allo sviluppo incrementando di conseguenza il conteggio del numero di termini. I
coefficienti dello sviluppo vengono aggiornati con gli elementi del vettore valor medio
calcolato mediante la (\ref{mu})
Se invece la mossa viene rifiutata i termini dello sviluppo rimangono gli stessi mentre
si aggiornano i coefficienti dello sviluppo e viene estratta una nuova varianza per i
coefficienti.
\subsection{Mossa di morte}
\hrule 
\textbf{Algorithm 3} Mossa di morte
\hrule

\begin{algorithmic}
\State All'iterazione $i$ estrai casualmente un termine di processo $p^{(i)}$ da quelli attualmente  selezionati
\State Calcola la quantità $r_a$
\State Calcola il rapporto di accettazione della mossa di morte $\gamma_{\textit{death}}^{(k)}$
\State Estrai $z_d\in\unif$
\If{$z_d\geq\gamma_{\textit{death}}^{(k)}$}
\State k:=k-1
\State $ \mathcal{P}_k^{(i)}= \mathcal{P}_k^{(i-1)}- \{p^{(i)}\} $
\State aggiornare i parametri con il valor medio della proposal $\ak:=\mu_{a,k'}$
\Else
\State Aggiorna i parametri usando (l'algoritmo 3)
\State Aggiorna la varianza $\va$
\EndIf
\end{algorithmic}
\hrule
\vspace{2em}
Il termine da eliminare dallo sviluppo viene scelto casualmente (con probabilità
uniforme) tra i termini già presenti nell’attuale modello
Una volta scelto il termine candidato è necessario decidere se accettare o meno la
mossa di morte alla maniera di RJMCMC, in modo da far convergere la catena
all’equilibrio rappresentato dalla posterior dei modelli
In particolare si accetta la mossa di morte con probabilità
\begin{equation}
\gamma_{\textit{birth}}^{(k)}=min\left\lbrace 1,r_a\right\rbrace
\end{equation}
Con $r_a$ ottenuto mediante l’equazione (\ref{ra})
Per imporre la probabilità di accettazione viene estratto un numero da una distribuzione
 $z_d\in\unif$,si accetta la
mossa se $z_d\geq \gamma_{\textit{death}}^{(k)}$ birth e si rifiuta se $z_b> \gamma_{\textit{death}}^{(k)}$ .
Dunque se la mossa di morte viene accettata, il termine proposto viene eliminato
dallo sviluppo e reinserito tra i termini disponibili per le future mosse di nascita,viene
decrementato di conseguenza il conteggio del numero di termini. I coefficienti dello
sviluppo vengono aggiornati con gli elementi del vettore valor medio calcolato mediante la (\ref{mu}).
Se invece la mossa viene rifiutata i termini dello sviluppo rimangono gli stessi mentre
si aggiornano i coefficienti dello sviluppo e viene estratta una nuova varianza per i
coefficienti.
\subsection{Aggiornamento dei parametri}
\hrule 
\textbf{Algorithm 5} Aggiornamento dei parametri
\hrule

\begin{algorithmic}
\For{m=1:k}
\State Estrarre un candidato $\hat{a_m}^{(i)}\sim\mathcal{N}(a_m^{(i-1)},C_{m,m})$ per $a_m^{(i)}$ 
\State Porre $a_{-m}^{(i)}=a_{-m}^{(i-1)}$
\State Calcolare la probabilità di accettazione
\[
\alpha(\hat{a_m}^{(i)}|a_m^{(i-1)})=\min\left\lbrace 1, \frac{p(\hat{a_m}^{(i)}|a_{-m}^{(i-1)},\y) q(a_{-m}^{(i-1)}|a^{(i)})}{p(a_m^{(i-1)}|a_{-m}^{(i-1)},\y)q(\hat{a_m}^{(i)}|a^{(i-1)}} \right\rbrace
\]
\State $z\sim\unif$
\If {$z\geq \alpha(\hat{a_m}^{(i)}|a_m^{(i-1)})$}
\State $a_m^{(i)}=\hat{a}_m^{(i-1)}$
\Else
\State $a_m^{(i)}=a_m^{(i-1)}$
\EndIf
\EndFor
\end{algorithmic}
L’aggiornamento dei parametri viene fatto campionando la ddp a posteriori dei
parametri stessi
\begin{equation}
p(\ak|\y,k,\pk,\eq,\va)
\end{equation}
che usando Bayes può essere espressa come

\begin{equation}
p(\ak|\y,k,\pk,eq,\va)\propto p(\y|\pk,\eq,\ak,\bq,\ve)p(\ak|k,\va)\propto exp\left\lbrace- \frac{\epsilon^T\epsilon}{2\ve}\right\rbrace p(\ak|k,\va)
\end{equation}
con
\begin{equation}
\epsilon=\y-\pk\ak-\eq\bq
\end{equation}
e
\begin{equation}
p(\ak|k,\va)=\normal{\textbf{0}}{\va \mathbb{I}}
\end{equation}
I parametri sono aggiornati sequenzialmente usando un algoritmo di tipo MH che,
invece di campionare la posterior multivriata la approssima campionando la probabilità dei singoli coefficienti condizionate rispetto agli altri. Dato però che anche le
singole probabilità condizionate non sono semplici da campionare, si ricorre ad una
densità di proposal scelta come gaussiana di varianza $C_{m,m}$ (l’ m-esimo elemento
della diagonale della matrice $C_{a,k}$ ) e valor medio il vecchio coefficiente $a_m^{(i-1)}$ . Il
coefficiente proposto viene accettato (sostituito al posto del corrispondente vecchio
coefficiente) con una probabilità che è calcolata alla maniera di MH.
\begin{equation}
\alpha(\hat{a}_m^{(i)}|a_m^{(i-1)})=min\left\lbrace 1,\frac{p(\hat{a}_m^{(i)}|a_{-m}^{(i-1)},\y)q(a_{-m}^{(i-1)}|a^{(i)})}
{p(a_{-m}^{(i-1)}|a_{-m}^{(i-1)},\y)q(\hat{a}_m^{(i)}|a^{(i)})})\right\rbrace
\end{equation}
Nella espressione sopra si è omesso il simbolo k che indica la struttura di modello a
cui si riferisce il vettore di coefficienti. Se non c’è il pedice si indica tutto il vettore
dei coefficienti. Il simbolo di accento circonflesso indica l’elemento estratto dalla
proposal. Il pedice m indica che si sta parlando dell’m-esimo elemento del vettore,
il pedice -m indica il vettore di tutti i coefficienti escluso l’m-esimo. L’apice indica
l’iterazione di RJMCMC in cui è stato calcolato il termine: quelli che hanno apice
(i-1) sono i vecchi coefficienti mentre quelli con apice (i) sono quelli calcolati
nell’attuale iterazione. Con probabilità $1-\alpha(\hat{a}_m^{(i)})|a_m^{(i-1)}$ il coefficiente proposto
viene rifiutato e rimane pari al vecchio valore.
